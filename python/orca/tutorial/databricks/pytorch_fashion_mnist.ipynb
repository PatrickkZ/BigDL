{"cells":[{"cell_type":"code","source":["from __future__ import print_function\nimport os\nimport argparse\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom bigdl.orca import init_orca_context, stop_orca_context\nfrom bigdl.orca.learn.pytorch import Estimator\nfrom bigdl.orca.learn.metrics import Accuracy\nfrom bigdl.orca.learn.trigger import EveryEpoch\n\n\ndef train_data_creator(config={}, batch_size=4, download=True, data_dir='./data'):\n    transform = transforms.Compose(\n        [transforms.ToTensor(),\n         transforms.Normalize((0.5,), (0.5,))])\n\n    trainset = torchvision.datasets.FashionMNIST(root=data_dir,\n                                                 download=download,\n                                                 train=True,\n                                                 transform=transform)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                              shuffle=True, num_workers=0)\n    return trainloader\n\n\ndef validation_data_creator(config={}, batch_size=4, download=True, data_dir='./data'):\n    transform = transforms.Compose(\n        [transforms.ToTensor(),\n         transforms.Normalize((0.5,), (0.5,))])\n    testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False,\n                                                download=download, transform=transform)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                             shuffle=False, num_workers=0)\n    return testloader\n\n\n# helper function to show an image\ndef matplotlib_imshow(img, one_channel=False):\n    if one_channel:\n        img = img.mean(dim=0)\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    if one_channel:\n        plt.imshow(npimg, cmap=\"Greys\")\n    else:\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\ndef model_creator(config):\n    model = Net()\n    return model\n\n\ndef optimizer_creator(model, config):\n    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n    return optimizer"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe39d27d-db0f-484e-8a6d-cddd922f537a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["cluster_mode = \"spark-submit\"\nbackend = \"ray\" # ray or spark\nbatch_size = 4\nepochs = 2\ndata_dir = \"./data\"\ndownload = True\nmodel_dir = \"/dbfs/FileStore/model/fashion/\"\nsave_path = model_dir + \"fashion.pth\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"685f3e4b-95ad-4506-b8f2-626838cd6c58"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["init_orca_context(cluster_mode=cluster_mode)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9ef440c-340f-47ad-a76f-840c9069d29e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# constant for classes\nclasses = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n\n# plot some random training images\ndataiter = iter(train_data_creator(config={}, batch_size=4,\n                                   download=download, data_dir=data_dir))\nimages, labels = dataiter.next()\n\n# create grid of images\nimg_grid = torchvision.utils.make_grid(images)\n\n# show images\nmatplotlib_imshow(img_grid, one_channel=True)\n\n# training loss vs. epochs\ncriterion = nn.CrossEntropyLoss()\nbatch_size = batch_size\nepochs = epochs\n\norca_estimator = Estimator.from_torch(model=model_creator,\n                                      optimizer=optimizer_creator,\n                                      loss=criterion,\n                                      metrics=[Accuracy()],\n                                      model_dir=model_dir,\n                                      use_tqdm=True,\n                                      backend=backend)\n\nstats = orca_estimator.fit(train_data_creator, epochs=epochs, batch_size=batch_size)\n\nprint(\"Train stats: {}\".format(stats))\nval_stats = orca_estimator.evaluate(validation_data_creator, batch_size=batch_size)\nprint(\"Validation stats: {}\".format(val_stats))\n    \nprint(\"Saving model to: \", save_path)\norca_estimator.save(save_path)\n    \n# load with orca_estimator.load(save_path)\n# orca_estimator.load(save_path)\n\norca_estimator.shutdown()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae97244e-365a-4295-8d70-6e75d9a3fcaa"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["stop_orca_context()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d8125fdd-04c7-4e94-9b57-1d621da7a54c"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"fashion_mnist_example","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3334158901214314}},"nbformat":4,"nbformat_minor":0}
